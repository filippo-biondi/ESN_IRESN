{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with open(r\"./Data/dataset_n306_X_500_12.pickle\", \"rb\") as input_file:\n",
    "    dataset = pickle.load(input_file)\n",
    "\n",
    "(x_dataset, y_dataset, labels) = dataset\n",
    "permutation = list(range(x_dataset.shape[0]))\n",
    "\n",
    "# if you need to shuffle the dataset\n",
    "random.shuffle(permutation)\n",
    "\n",
    "x_dataset = np.array([x_dataset[i] for i in permutation])\n",
    "y_dataset = np.array([y_dataset[i] for i in permutation])\n",
    "labels = np.array([labels[i] for i in permutation])\n",
    "\n",
    "leads = [6, 7, 8] # V1 V2 V3\n",
    "n_leads = len(leads)\n",
    "x_dataset = np.take(x_dataset, leads, axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from search import *\n",
    "from Models.model_buiders import *\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from accuracy_plotter import accuracy_plotter\n",
    "\n",
    "n_out_fold = 5\n",
    "kf_out = KFold(n_splits=n_out_fold)\n",
    "results = []\n",
    "\n",
    "for fold in range(n_out_fold):\n",
    "    print(\"fold \", fold)\n",
    "    train_val_index, test_index = list(kf_out.split(x_dataset))[fold]\n",
    "\n",
    "    hp = {\"units\": 1200, \"input_scaling\": 1.0, \"bias_scaling\": 0.1, \"inter_scaling\": None, \"spectral_radius\": 0.999,\n",
    "          \"leaky\": 0.1, \"learning_rate\": 0.01, \"sub_reservoirs\": n_leads}\n",
    "    trainedIRESN = build_TrainableIRESN(hp)\n",
    "    x_trainval, y_trainval,  = x_dataset[train_val_index], y_dataset[train_val_index],\n",
    "    x_test, y_test = x_dataset[test_index], y_dataset[test_index]\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_trainval, y_trainval, test_size=0.25)\n",
    "    hist = trainedIRESN.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=1000,\n",
    "                            batch_size=1000, verbose=1,\n",
    "                            callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=100,\n",
    "                                                                     restore_best_weights=True)])\n",
    "    accuracy_plotter(hist, \"./Plot/plot_\" + str(fold))\n",
    "    train_acc = trainedIRESN.evaluate(x_train, y_train, batch_size=1000)[1]\n",
    "    val_acc = trainedIRESN.evaluate(x_val, y_val, batch_size=1000)[1]\n",
    "    test_acc = trainedIRESN.evaluate_precise(x_test, y_test)\n",
    "\n",
    "    result = {}\n",
    "    result[\"train_acc\"] = train_acc\n",
    "    result[\"val_acc\"] = val_acc\n",
    "    result[\"test_acc\"] = test_acc[0]\n",
    "    result[\"sens\"] = test_acc[1]\n",
    "    result[\"spec\"] = test_acc[2]\n",
    "    result[\"hist\"] = hist.history\n",
    "\n",
    "    learned_hp = {\"units\": 1200, \"input_scaling\": list(trainedIRESN.trainable_weights[0].numpy().ravel()),\n",
    "                  \"bias_scaling\": list(trainedIRESN.trainable_weights[1].numpy().ravel()),\n",
    "                  # \"inter_scaling\": list(trainedIRESN.trainable_weights[2].numpy().ravel()),\n",
    "                  \"inter_scaling\": None,\n",
    "                  \"spectral_radius\": list(trainedIRESN.non_trainable_weights[0].numpy().ravel()),\n",
    "                  \"leaky\": trainedIRESN.non_trainable_weights[1].numpy().ravel()[0], \"sub_reservoirs\": n_leads, \"reg\": None}\n",
    "    result[\"learned_hp\"] = learned_hp\n",
    "\n",
    "    IRESNDirect = build_IRESN(learned_hp)\n",
    "    IRESNDirect.reservoir = trainedIRESN.reservoir\n",
    "    train_final, val_final, reg = k_fold_val_reg(IRESNDirect, x_trainval, y_trainval, n_fold=4)\n",
    "    IRESNDirect.fit(x_trainval, y_trainval, reg=reg)\n",
    "    test_final = IRESNDirect.evaluate_precise(x_test, y_test)\n",
    "    readout_weights = IRESNDirect.readout.coef_\n",
    "    result[\"weights\"] = readout_weights\n",
    "\n",
    "    result[\"reg\"] = reg\n",
    "    result[\"train_final\"] = train_final\n",
    "    result[\"val_final\"] = val_final\n",
    "    result[\"test_final\"] = test_final[0]\n",
    "    result[\"sens_final\"] = test_final[1]\n",
    "    result[\"spec_final\"] = test_final[2]\n",
    "\n",
    "    results.append(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train = []\n",
    "val = []\n",
    "test = []\n",
    "spec = []\n",
    "sens = []\n",
    "train_f = []\n",
    "val_f = []\n",
    "test_f = []\n",
    "sens_f = []\n",
    "spec_f = []\n",
    "hps = []\n",
    "for mod in results:\n",
    "    train.append(float(mod[\"train_acc\"]))\n",
    "    val.append(float(mod[\"val_acc\"]))\n",
    "    test.append(float(mod[\"test_acc\"]))\n",
    "    sens.append(float(mod[\"sens\"]))\n",
    "    spec.append(float(mod[\"spec\"]))\n",
    "    train_f.append(float(mod[\"train_final\"]))\n",
    "    val_f.append(float(mod[\"val_final\"]))\n",
    "    test_f.append(float(mod[\"test_final\"]))\n",
    "    sens_f.append(float(mod[\"sens_final\"]))\n",
    "    spec_f.append(float(mod[\"spec_final\"]))\n",
    "    hps.append(mod[\"learned_hp\"])\n",
    "\n",
    "train = np.array(train)\n",
    "val = np.array(val)\n",
    "test = np.array(test)\n",
    "spec = np.array(spec)\n",
    "sens = np.array(sens)\n",
    "train_f = np.array(train_f)\n",
    "val_f = np.array(val_f)\n",
    "test_f = np.array(test_f)\n",
    "sens_f = np.array(sens_f)\n",
    "spec_f = np.array(spec_f)\n",
    "\n",
    "with open(fr\"./result_train_IRESN_{n_leads}.txt\", \"w\") as output_file:\n",
    "    print(\"leads: \", leads, file=output_file)\n",
    "    print(\n",
    "        rf\"${round(train.mean(), 3)} \\pm {round(train.std(), 4)}$ & ${round(val.mean(), 3)} \\pm {round(val.std(), 4)}$ & ${round(test.mean(), 3)} \\pm {round(test.std(), 4)}$ & ${round(sens.mean(), 3)} \\pm {round(sens.std(), 4)}$ & ${round(spec.mean(), 3)} \\pm {round(spec.std(), 4)}$\", file=output_file\n",
    "    )\n",
    "    print(\n",
    "        rf\"${round(train_f.mean(), 3)} \\pm {round(train_f.std(), 4)}$ & ${round(val_f.mean(), 3)} \\pm {round(val_f.std(), 4)}$ & ${round(test_f.mean(), 3)} \\pm {round(test_f.std(), 4)}$ & ${round(sens_f.mean(), 3)} \\pm {round(sens_f.std(), 4)}$ & ${round(spec_f.mean(), 3)} \\pm {round(spec_f.std(), 4)}$\", file=output_file\n",
    "    )\n",
    "    print(\"learned hp\", file=output_file)\n",
    "    for hp in hps:\n",
    "        print(hp, file=output_file)\n",
    "\n",
    "    print(\"training iter\", train, file=output_file)\n",
    "    print(\"validation iter\", val, file=output_file)\n",
    "    print(\"test iter\", test, file=output_file)\n",
    "    print(\"sensitivity iter\", sens, file=output_file)\n",
    "    print(\"specificity iter\", spec, file=output_file)\n",
    "    print(\"training direct\", train_f, file=output_file)\n",
    "    print(\"validation direct\", val_f, file=output_file)\n",
    "    print(\"test direct\", test_f, file=output_file)\n",
    "    print(\"sensitivity direct\", sens_f, file=output_file)\n",
    "    print(\"specificity direct\", spec_f, file=output_file)\n",
    "\n",
    "    w = [[] for _ in range(n_leads)]\n",
    "    for mod in results:\n",
    "        coeff = mod[\"weights\"].ravel()[:-1]\n",
    "        coeff = coeff / np.linalg.norm(coeff)\n",
    "        splitted = np.split(coeff, n_leads)\n",
    "        for j, s in enumerate(splitted):\n",
    "            w[j].append(np.linalg.norm(s) ** 2)\n",
    "    for i in range(n_leads):\n",
    "        w[i] = np.array(w[i])\n",
    "        w[i] = (w[i].mean(), w[i].std())\n",
    "        print(rf\"leads {i}: ${round(w[i][0], 3)} \\pm {round(w[i][1], 4)}$\", file=output_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
